#!/usr/bin/env python

import os, sys, string, types, re, exceptions, signal, time
import gzip, argparse
import dp_utils, ticker_lib, dp_io, dp_time, dp_sequences
from dp_object import dp_object

Caught_signals = []

## Tickers
## Tickers count "lines of input." This is really just the number of calls to
## the ticker instance's __call__() method.
## A base ticker does it with number of lines.
## A char ticker does it with characters.
## A twiddle ticker ticks in one place, cycling through a char set, like
## bsd's boot ticker.

## Teeker
## Char wise means split input lines into chars and feed them 1 by 1 into the
## ticker. This can be any kind of ticker. Each character is one "line" of
## input to the underlying ticker.

## @todo XXX Add prefix status string.
## E.g. track number of grep hits (or just the fact that any have occurred).
## Right now there is the ability to add a timestamp, sampled line count and
## sample prefix.
## A prefix format string driven by a dictionary. Roughly:
## "%(timestamp)s %(sample_count)s %(sample_prefix)" just as a starting point.
## Print everything as a string, i.e. use %(x)s so that we can use strings to
## pad when something isn't used.
## E.g.  if we're not timestamping, then prefix_dict["timestamp"] = " " *
## timestamp_field_width.
## It'll be annoying to have to update the dict for rapidly changing values
## like sample count or grep hits. There may be a better way.
## @todo XXX Add prefix status string.

## @todo XXX Add remote control via signals or other method.
## Motivation: Send a signal and have it dump all current grep hits.

# Regular variable names are strings. So we'll use a non-string for some
# special, internal codes. This `var' holds the constructor of the chosen
# Ticker*_t
# There cannot be an accidental name collision this way.
class CTOR_t:
    def __init__(self):
        self.info = "I am the key of the appropriate ticker constructor."


Match_types = {}

DEFAULT_ERROR_INDICATOR = "!"
DEFAULT_EGREP_PREFIX = DEFAULT_ERROR_INDICATOR * 4
DEFAULT_EGREP_SUFFIX = DEFAULT_ERROR_INDICATOR * 4

DEFAULT_MATCH_INDICATOR = "+"
DEFAULT_MATCH_PREFIX = DEFAULT_MATCH_INDICATOR * 3
DEFAULT_MATCH_SUFFIX = DEFAULT_MATCH_INDICATOR * 3

DEFAULT_WARNING_INDICATOR = "*"
DEFAULT_WARNING_PREFIX = DEFAULT_WARNING_INDICATOR * 3
DEFAULT_WARNING_SUFFIX = DEFAULT_WARNING_INDICATOR * 3

DEFAULT_INDICATOR_SEPARATOR = "|"
DEFAULT_MAX_ERROR_MATCHES = 0
DEFAULT_LINES_AFTER = 0                 # None
DEFAULT_FLUSH_BYTES = 0

REGEXP_LIST_ORDER = ("grep", "hgrep", "wgrep", "egrep")
#tick_counter_count_format = "%8d"

# '{:.>30}'.format(9)
TICKER_COUNT_WIDTH = 8
TICKER_COUNT_FILL_CHAR = "."
TICKER_COUNT_JUSTIFICATION = ">"
TICKER_COUNT_FORMAT = ("{:"
                       + TICKER_COUNT_FILL_CHAR
                       + TICKER_COUNT_JUSTIFICATION
                       + str(TICKER_COUNT_WIDTH)
                       + "}")

# The timestamp is generated inside the ticker object.
# This will need to track that.
timestamp_width = len("2013-05-16T18.37.54")

CTOR = CTOR_t()

def make_tick_prefix():
    if len(Match_types):
        match_indicators = Match_types.values()
        match_indicators.sort()
        return "".join(match_indicators) + DEFAULT_INDICATOR_SEPARATOR
    return ""

def make_sample_tick(num, width=8, fill_char=".",
                     prefix="", suffix=""):
    num_string = "{}".format(num)
    rem = width - len(num_string)
    if (rem > 0):
        fill = fill_char * rem
    else:
        fill = ""
    return prefix + fill + num_string + suffix
    
def display_match(ostream, line, line_number, prefix="", suffix="",
                  timestamp_p=False):
    if timestamp_p:
        ts = dp_time.std_timestamp() + ": "
    else:
        ts = ""
    pline = "{} {}line: {}, >{}< {}".format(prefix,
                                            ts,
                                            line_number,
                                            line,
                                            suffix)
    if pline[-1] != "\n":
        pline = pline + "\n"
    dp_io.fprintf(ostream, "{}".format(pline))

##     dp_io.fprintf(sys.stderr, "prefix>{}<, ts>{}<, line: num>{}<, >{}< suf>{}<".format(prefix, ts,
##                                                            line_number,
##                                                            line, suffix))
    ostream.flush()

class Grep_list_t(dp_object):
    def __init__(self,
                 regexps,
                 indicator_char="",
                 match_prefix=None,
                 timestamp_p=False,
                 match_suffix=None,
                 max_matches=None,
                 match_action=None,
                 ostream=None,
                 description="Regexp"):
        self.d_indicator_char = indicator_char
        self.d_max_matches = max_matches
        self.d_regexps = []
        self.d_compiled_regexps = []
        self.d_matching_lines = []
        self.d_compiled_p = False
        self.d_num_matches = 0
        self.d_match_action = match_action
        self.d_ostream = ostream
        if match_prefix == None:
            match_prefix = indicator_char * 3
        self.d_match_prefix = match_prefix
        if match_suffix == None:
            match_suffix = indicator_char * 3
        self.d_match_suffix = match_suffix
        self.d_timestamp_p = timestamp_p
        if regexps:
            self.compile_and_add_regexps(regexps)
        else:
            self.d_compiled_regexps = []
        self.d_description = description
        Match_types[self.d_description] = "-"

    def num_matches(self):
        return len(self.d_matching_lines)

    def highlights_p(self):
        return self.d_indicator_char

    def matches(self):
        return self.d_matching_lines

    def compile_and_add_regexps(self, regexps):
        if not regexps:
            regexp = self.d_regexps
        for regexp in regexps:
            self.d_compiled_regexps.append(re.compile(regexp))

    def max_matches_handler(self, line, line_number):
        fmt = "Default Max matches handler, line: >{}<, line_number: {}"
        print >>self.d_ostream, fmt.format(line, line_number)
        return False

    def match_handler(self, match_object, line, line_number, ostream=None,
                      timestamp_p=None):
        Match_types[self.d_description] = self.d_indicator_char
        self.d_matching_lines.append((line, line_number))
        self.d_num_matches += 1
        self.print_matches(match=(line, line_number), ostream=ostream,
                           timestamp_p=timestamp_p)
        if self.d_match_action:
            self.print_action(dp_io.bq("{} {}".format(self.d_match_action,
                                                      line)))
        if ((self.d_max_matches is not None)
            and
            (self.d_num_matches > self.d_max_matches)):
            ret = self.max_matches_handler(line, line_number)
        return True

    def match(self, line, line_number, ostream=None, timestamp_p=None):
        appended_p = False
        continue_p = True
        ret = False                     # Did we overflow?
        line = line[:-1]
        for regexp in self.d_compiled_regexps:
            m = regexp.search(line)
            if m:
                ret = self.match_handler(m, line, line_number, ostream,
                                         timestamp_p)
        return ret

    def dump_matches(self, all_output_streams, title, matching_lines=None,
                     dump_empty_lists_p=False):
        if matching_lines is None:
            matching_lines = self.d_matching_lines
        if not dump_empty_lists_p and not matching_lines:
            return
        header_lines = ["\n" + title + "\n",
                        ("%s matches: %s\n" % (self.d_description,
                                               len(matching_lines))),
                        ("Num matching lines: %s\n" % (len(matching_lines),))]
        for lt in  header_lines + matching_lines:
            if type(lt) == types.TupleType:
                num = TICKER_COUNT_FORMAT.format(lt[1])
                format = "Matching line[{}]: {}>{}<\n".format(
                    self.d_indicator_char, num, "{}")
##                 print "format>{}<".format(format)
                s = lt[0]
            else:
                format = "{}"
                s = lt
            for o in all_output_streams:
                o.write(format.format(s))

    def print_matches(self, match=None, ostream=None, timestamp_p=None):
        if not ostream:
            ostream = self.d_ostream
        if match != None:
            matches = [match]
        else:
            matches = self.d_matching_lines
        if ostream:
            if timestamp_p == None:
                timestamp_p = self.d_timestamp_p
            for line, line_number in matches:
                display_match(ostream, line, line_number,
                              prefix="\n" + self.d_match_prefix,
                              suffix=self.d_match_suffix + "\n",
                              timestamp_p=timestamp_p)

    def print_action(self, s, ostream=None, timestamp_p=None):
        if not ostream:
            ostream = self.d_ostream
            dp_io.fprintf(ostream, "{}".format(s))


class Hgrep_list_t(Grep_list_t):
    def __init__(self,
                 regexps,
                 indicator_char=DEFAULT_MATCH_INDICATOR,
                 match_prefix=None,
                 timestamp_p=False,
                 match_suffix=None,
                 max_matches=None,
                 match_action=None,
                 ostream=sys.stdout,
                 description="Highlighted regexp"):
        Grep_list_t.__init__(self,
                             regexps=regexps,
                             indicator_char=indicator_char,
                             match_prefix=match_prefix,
                             timestamp_p=timestamp_p,
                             match_suffix=match_suffix,
                             max_matches=max_matches,
                             ostream=ostream,
                             match_action=match_action,
                             description=description)

class Wgrep_list_t(Hgrep_list_t):
    def __init__(self,
                 regexps,
                 indicator_char=DEFAULT_WARNING_INDICATOR,
                 match_prefix=None,
                 timestamp_p=False,
                 match_suffix=None,
                 max_matches=None,
                 match_action=None,
                 ostream=sys.stdout,
                 description="Warning regexp"):
        Hgrep_list_t.__init__(self,
                              regexps=regexps,
                              indicator_char=indicator_char,
                              match_prefix=match_prefix,
                              timestamp_p=timestamp_p,
                              match_suffix=match_suffix,
                              max_matches=max_matches,
                              match_action=match_action,
                              ostream=ostream,
                              description=description)

class Egrep_list_t(Grep_list_t):
    def __init__(self,
                 regexps,
                 indicator_char=DEFAULT_ERROR_INDICATOR,
                 match_prefix=None,
                 timestamp_p=False,
                 match_suffix=None,
                 max_matches=None,
                 match_action=None,
                 ostream=sys.stderr,
                 description="Error regexp"):
        Grep_list_t.__init__(self,
                             regexps=regexps,
                             indicator_char=indicator_char,
                             match_prefix=match_prefix,
                             timestamp_p=timestamp_p,
                             match_suffix=match_suffix,
                             max_matches=max_matches,
                             match_action=match_action,
                             ostream=ostream,
                             description=description)

    def max_matches_handler(self, line, line_number):
        print >>self.d_ostream, "Max error matches exceeded."
        return True
    
parse_debug = 0

def signal_handler(signal, frame):
    Caught_signals.append("%s" % (signal,))

signal.signal(signal.SIGINT, signal_handler)


def identity(x, *args, **kw_args):
    if args:
	return [x] + args
    return x

def true(*args, **kwargs):
    return True

def false(*args, **kwargs):
    return False

def Catlike_setup(namespace):
    setattr(namespace, "sample_lines_tick_p", True)
    setattr(namespace, "tick_interval", 1)
    setattr(namespace, "sample_lines_tick_prefix", False)
    setattr(namespace, "tee_p", True)

def eval_with_units(num, allow_fractions_p=False):
    if (num == "-1"):
        return False                    # No limit
    return dp_utils.numWithUnits(num, allow_fractions_p=allow_fractions_p)

def eval_with_units_fractions_ok(num):
    return eval_with_units(num, allow_fractions_p=True)

# Funnel through here for debugging.
def add_to_dict_action(actor, dictionary, parser, namespace, values,
                       option_string=None, dest=None, ext_dict=False):
    if parse_debug:
        print 'dest: %s, ns: %r, values: %r, ostr: %r' % (actor.dest,
                                                          namespace,
                                                          values,
                                                          option_string)
    dest = dest or actor.dest
    if ext_dict:
        dictionary.update(ext_dict)
    else:
        dictionary[dest] = values
    if type(dest) == types.StringType:
        setattr(namespace, dest, values)

App_arg_dict = {CTOR: ticker_lib.Ticker_t}

Ctor_arg_dict = {}

class Ctor_arg_action(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None,
                 dest=None, ext_dict=False):
        add_to_dict_action(self, Ctor_arg_dict, parser, namespace,
                           values, option_string, dest=dest,
                           ext_dict=ext_dict)

class App_arg_action_ctor(Ctor_arg_action):
    def __call__(self, parser, namespace, values, option_string=None,
                 dest=None, ext_dict=False):
        add_to_dict_action(self, App_arg_dict, parser, namespace,
                           ticker_lib.Char_ticker_t,
                           option_string, CTOR)
        add_to_dict_action(self, App_arg_dict, parser, namespace, True,
                           dest="char_wise_p")

class Ctor_arg_action_true(Ctor_arg_action):
    def __call__(self, parser, namespace, values, option_string=None):
        add_to_dict_action(self, Ctor_arg_dict, parser, namespace, True,
                           option_string=None)

class Ctor_arg_action_false(Ctor_arg_action):
    def __call__(self, parser, namespace, values, option_string=None):
        add_to_dict_action(self, Ctor_arg_dict, parser, namespace, False,
                           option_string=None)

class Ctor_arg_action_char(Ctor_arg_action):
    def __call__(self, parser, namespace, values, option_string=None):
        add_to_dict_action(self, Ctor_arg_dict, parser, namespace, values,
                           option_string=None)
        add_to_dict_action(self, App_arg_dict, parser, namespace,
                           ticker_lib.Char_ticker_t,
                           option_string, CTOR)

class Ctor_arg_action_dots(Ctor_arg_action_char):
    def __call__(self, parser, namespace, values, option_string=None):
        Ctor_arg_action_char.__call__(self, parser, namespace, ".",
                                      option_string=option_string)
    
class Ctor_arg_action_char_and_char_wise(Ctor_arg_action_char):
    def __call__(self, parser, namespace, values, option_string=None):
        Ctor_arg_action_char.__call__(self, parser, namespace, values,
                                     option_string=option_string)
        add_to_dict_action(self, App_arg_dict, parser, namespace, True,
                           dest="char_wise_p")

class Ctor_arg_action_dots_and_char_wise(Ctor_arg_action_char_and_char_wise):
    def __call__(self, parser, namespace, values, option_string=None):
        Ctor_arg_action_char_and_char_wise.__call__(self,
                                                    parser, namespace, ".",
                                                    option_string=option_string)

#
# Set tick interval to value, set tick_char to "."
class App_arg_action_DOTS(argparse.Action):
    # set interval
    def __call__(self, parser, namespace, values, option_string=None):
        add_to_dict_action(self, App_arg_dict, parser, namespace,
                           ticker_lib.Char_ticker_t,
                           option_string, CTOR)
        setattr(namespace, self.dest, values)
        # Set tick char = '.'
        add_to_dict_action(self, Ctor_arg_dict, parser, namespace, ".",
                           dest="tick_char")

class App_arg_action_catlike(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        # Just be a pass through. Useful with -g.
        Catlike_setup(namespace)

class App_arg_action_add_regexp_and_highlight(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        regexps = getattr(namespace, self.dest)
        regexps.append(values)
        setattr(namespace, self.dest, regexps)

class App_arg_action_add_regexp_and_warning_highlight(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        regexps = getattr(namespace, self.dest)
        regexps.append(values)
        setattr(namespace, self.dest, regexps)

Convenience_opts = (("U_extension", ".log"), ("timestamp_log_file_names_p", True))

def set_convenience_opts(namespace):
    for name, val in Convenience_opts:
        setattr(namespace, name, val)

def show_convenience_opts():
    ret = ""
    l = len(Convenience_opts)
    if l > 1:
        sep = ", "
    for name, val in Convenience_opts:
        if l == 1:
            sep = ""
        ret += "%s: %s" % (name, val) + sep
        l -= 1
    return ret

class App_action_log_file_convenience(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        set_convenience_opts(namespace)
        setattr(namespace, "output_files_required_p", True)

class App_action_log_file_convenience_sampled(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        set_convenience_opts(namespace)
        setattr(namespace, "sample_lines_tick_p", True)
        setattr(namespace, "output_files_required_p", True)

class App_action_log_file_convenience_sampled_timestamped(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        set_convenience_opts(namespace)
        setattr(namespace, "sample_lines_tick_p", True)
        setattr(namespace, "output_files_required_p", True)
        Ctor_arg_dict["timestamp_p"] = True

class App_action_log_file_convenience_test_log(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        # --slog -Z9 --ts --hg -i100 --cflush-every=-1
        # --slog
        set_convenience_opts(namespace)
        setattr(namespace, "sample_lines_tick_p", True)
        setattr(namespace, "output_files_required_p", True)

        setattr(namespace, "compression_level", 9)               # -Z9
        Ctor_arg_dict["timestamp_p"] = True                      # --ts
        setattr(namespace, "highlight_ALL_grep_matches_p", True) # --hg
        setattr(namespace, "tick_interval", 100)                 # -i100
        setattr(namespace, "compressed_file_flush_period", -1)   # --cflush=-1


class Ctor_arg_action_twiddle(Ctor_arg_action):
    def __call__(self, parser, namespace, values, option_string=None):
        Ctor_arg_action.__call__(self, parser, namespace, values,
                                 option_string=None)
        add_to_dict_action(self, App_arg_dict, parser, namespace,
                           ticker_lib.Twiddle_ticker_t,
                           option_string, CTOR)


# Clean this whole thing up so that the lines are displayed in the objects.
def dump_matching_and_error_lines(output_streams,
                                  regexp_lists,
                                  wing_size=7,
                                  wing_string="=",
                                  extra_streams=[]):
    all_output_streams = output_streams
    dp_sequences.maybe_add_list_to_list(all_output_streams, extra_streams)
    wing = wing_size * wing_string
    #sep_line = len(title) * "="
    # Dump things so that the most "important" are last so they are the most
    # noticeable.
    for regexp_list in regexp_lists:
        title = "{} {} line summary {}".format(wing,
                                               regexp_list.d_description,
                                               wing)
        regexp_list.dump_matches(all_output_streams, title)
    
if __name__ == "__main__":
    import optparse
    def_tick_interval = 100
    ostream = sys.stdout
    default_match_ostream = sys.stdout
    def_pipe_stream = sys.stdout
    pipe_stream = def_pipe_stream
    open_mode = 'w'
    output_streams = []
    file_suffix = ""
    error_indicator = " "
    match_indicator = " "
    indicator_separator = " "
    line_number = 0
    Ctor_arg_dict["max_output_units_before_newline"] = 80 * 100
    append_p = False
    default_compression_level = 5
    GZIP_MAX_COMPRESSION_LEVEL = 9
    total_bytes_written = 0
    ## Each -Z adds one, and we want a single -Z to yield max compression.

    # tick_interval, increment=1, init_string="counting: ", comma=", ",
    # init_count=0, tick_char

    oparser = argparse.ArgumentParser()

    oparser.add_argument("--debug",
                         dest="debug_level", type=int, default=0)
    oparser.add_argument("--quiet",
                         dest="quiet_p", default=False,
                         action="store_true",
                         help="Do not print informative messages.")
    oparser.add_argument("--no-preamble", "--no-pre",
                         dest="preamble_p", default=True,
                         action="store_false",
                         help="Do not print detail before beginning the loop.")
    oparser.add_argument("-i", "--tick-interval",
                         dest="tick_interval", type=eval_with_units,
                         default=def_tick_interval,
                         help="Sample all lines (-s -i1).")
    oparser.add_argument("-T", "--show-twiddles",
                         dest="show_twiddles_p", default=False,
                         action="store_true",
                         help="Show list of available twiddles.")
    oparser.add_argument("-s", "--sample-lines", "--sample",
                         dest="sample_lines_tick_p", default=False,
                         action="store_true",
                         help="Tick with input line samples.")
    oparser.add_argument("--sample-all", "--sall",
                         dest="sample_ALL_lines_tick_p", default=False,
                         action="store_true",
                         help="Tick with every input line.")
    oparser.add_argument("-S", "--sample-lines-prefix",
                         dest="sample_lines_tick_prefix", default="th-line>",
                         action=Ctor_arg_action,
                         help="Prefix for sampled lines.")
    oparser.add_argument("--no-clobber",
                         dest="no_clobber_p", default=False,
                         action="store_true",
                         help="Don't clobber existing files. Exit.")
    oparser.add_argument("-Z", "--compression-level",
                         dest="compression_level", type=int,
                         help="Compression level.")
    oparser.add_argument("-z", "--compress",
                         dest="compression_level",
                         const=default_compression_level,
                         action="store_const",
                         help=("Set compression level to default: %s."
                               % (default_compression_level,)))
    oparser.add_argument("-9", "--z9", "--gzip9",
                         dest="compression_level",
                         const=GZIP_MAX_COMPRESSION_LEVEL,
                         action="store_const",
                         help=("Set compression level to %s." %
                               (GZIP_MAX_COMPRESSION_LEVEL)))
    oparser.add_argument("--compressed-flush-every",
                         "--compressed-flush-bytes",
                         "--compressed-flush_after",
                         "--compressed-flush-len",
                         "--compressed-flush-interval",
                         "--cflush-every", "--cflush-bytes",
                         "--cflush_after",
                         "--cflush-len", "--cflush-interval",
                         dest="compressed_file_flush_period",
                         type=eval_with_units,
                         default=DEFAULT_FLUSH_BYTES,
                         help=("Flush periodically after this many bytes: %s. 0 means use libz's default. -1 means every line."
                               % (DEFAULT_FLUSH_BYTES,)))
    oparser.add_argument("-u", "--timestamp-log-files",
                         dest="timestamp_log_file_names_p", default=False,
                         action="store_true",
                         help="Add uniquifying timestamp to output file name.")
    oparser.add_argument("-U", "--no-timestamp-log-files",
                         dest="timestamp_log_file_names_p", default=False,
                         action="store_false",
                         help="Do not add uniquifying timestamp to output file name.")
    oparser.add_argument("-E", "--extension",
                         dest="U_extension", default="",
                         type=str,
                         help=("Addition output file extension. "
                         "Added last, after timestamp [if present]."))
    oparser.add_argument("-l", "--log-file",
                         dest="U_extension", const=".log",
                         action="store_const",
                         help="Add .log suffix.")
    oparser.add_argument("-add-log-file-name",
                         dest="optional_log_file_names",
                         action="append", default=[],
                         help="Add file names via an option to allow overriding.")

    oparser.add_argument("--log-file-name",
                         dest="optional_log_file_name",  default="",
                         help="Add file name via an option to allow overriding.")

    oparser.add_argument("--log",
                         dest="output_files_required_p", default=False,
                         nargs=0,
                         # Special action needed because multiple vars are
                         # being changed.
                         action=App_action_log_file_convenience,
                         help=("Save to log file with useful defaults:\n" +
                               show_convenience_opts()))
    oparser.add_argument("--slog", "--sampled-log",
                         dest="output_files_required_p", default=False,
                         nargs=0,
                         action=App_action_log_file_convenience_sampled,
                         help="As --log plus sampled ticking.")
    oparser.add_argument("--tslog", "--timestamped-sampled-log",
                         dest="output_files_required_p", default=False,
                         nargs=0,
                         action=App_action_log_file_convenience_sampled_timestamped,
                         help="As --slog plus timestamps on sampled lines.")
    oparser.add_argument("--test-log",
                         dest="output_files_required_p", default=False,
                         nargs=0,
                         action=App_action_log_file_convenience_test_log,
                         help="Good for tracking a test. E.g. --slog -Z9 --ts --hg -i100 --cflush-every=-1.")
    oparser.add_argument("--show-units",
                         dest="show_tick_units_p",
                         nargs=0,
                         action=Ctor_arg_action_true,
                         help="Print units [chars, lines] with output.")
    oparser.add_argument("--timestamp", "--ts",
                         dest="timestamp_p", default=False,
                         nargs=0,
                         action=Ctor_arg_action_true,
                         help="Add a timestamp to ticks. Nice with sampled output.")
    oparser.add_argument("--elapsed-timestamp", "--ets",
                         dest="elapsed_timestamp_p", default=False,
                         nargs=0,
                         action=Ctor_arg_action_true,
                         help="Add an elapsed timestamp to ticks. Nice with sampled output.")
    oparser.add_argument("-I", "--increment",
                         dest="increment", type=eval_with_units,
                         action=Ctor_arg_action,
                         help="Increment")
    oparser.add_argument("-m", "--max-output-line-len",
                         dest="max_output_units_before_newline",
                         type=eval_with_units,
                         action=Ctor_arg_action,
                         help="Maximum ticks per line")
    oparser.add_argument("-M", "--max-output",
                         dest="max_output_units_before_exit",
                         type=eval_with_units,
                         action=Ctor_arg_action,
                         help="Maximum ticks before exiting.")
    oparser.add_argument("--max-log-file-size", "--max-bytes-written",
                         dest="max_output_bytes_before_exit",
                         default=False,
                         type=eval_with_units,
                         help="Maximum bytes before exiting.")
    oparser.add_argument("-P", "--prefix", "--initial-string",
                         dest="init_string",
                         action=Ctor_arg_action,
                         help="Initial prefix string.")
    oparser.add_argument("-C", "--comma", "--count-separator", "--separator",
                         dest="comma",
                         action=Ctor_arg_action,
                         help="Separator character between ticks.")
    oparser.add_argument("--initial-count",
                         dest="init_count",
                         type=eval_with_units,
                         action=Ctor_arg_action,
                         help="Initial count [number of units]")
    oparser.add_argument("-c", "--tick-char",
                         dest="tick_char", default=None,
                         action=Ctor_arg_action_char,
                         help="""Tick character. Mutually exclusive with twiddle.
Implies Char_ticker_t""")
    oparser.add_argument("-d", "--dots",
                         dest="tick_char",
                         nargs=0,
                         action=Ctor_arg_action_dots,
                         help="Use dots for tick char. Implies Char_ticker_t.")
    oparser.add_argument("-.", "--char-dots",
                         dest="tick_char",
                         nargs=0,
                         action=Ctor_arg_action_dots_and_char_wise,
                         help="Char_ticker_t, count chars, tick with '.'.")
    oparser.add_argument("-D", "--DOTS",
                         dest="tick_interval",
                         type=eval_with_units,
                         action=App_arg_action_DOTS,
                         help="Like --dots + tick interval.")
    oparser.add_argument("-t", "--twiddle",
                         dest="twiddle_chars", type=int,
                         action=Ctor_arg_action_twiddle,
                         help="Set twiddle chars. Implies Twiddle_ticker_t")
    oparser.add_argument("-G", "--print-grand-total", "--grand-total",
                         dest="grand_total_p", default=True,
                         nargs=0,
                         action=Ctor_arg_action_false,
                         help="Print grand total at end.")
    oparser.add_argument("-k", "--char-wise",
                         dest="char_wise_p", default=False,
                         action="store_true",
                         help="""Count chars vs lines [the default].
Split line into chars and feed to ticker.""")
    oparser.add_argument("-K", "--char-wise-char", "--char-tick-char",
                         dest="tick_char",
                         nargs=0,
                         action=Ctor_arg_action_char_and_char_wise,
                         help="Count chars vs lines [the default] and set tick char.")
    oparser.add_argument("-p", "-e", "--pipe-mode", "--output-to-stderr",
                         "--tick-to-stderr",
                         dest="pipe_mode_p", default=False,
                         action="store_true",
                         help="Send ticks to stderr and input to stdout.")
    # Get names like this (perhaps as an envvar named like
    # <app-name>_specific_opt="--tgen-errors".  And
    # <app-name>_specific_opt_val="Blah"
    # Meh. Methinks tis not worth the effort given the need to provide
    # actions. There would need to be a kind of processor for each group of
    # variables.  Much easier to use wrapper scripts to provide the
    # values. And more flexible since each wrapper can provide its own set of
    # defaults.
    oparser.add_argument("--tgen-errors",
                         default=None, const="Assertion|call stack|stack_trace",
                         action="store_const",
                         help="Convenience option for finding common testgen errors. This should be modified to make it more flexible and less nvidia specific. Maybe an environment variable  --log-errors-regexp")
    oparser.add_argument("--grep-errors", "--errors", "--error-regexps",
                         "--ere", "--egrep", "--err-grep",
                         dest="error_regexp_patterns",
                         action="append", default=[],
                         help="Grep for these patterns and treat matches as errors. --max-errors tells how many error matches to accept before exiting. The default is %s where 0 means no limit." % (DEFAULT_MAX_ERROR_MATCHES,))
    oparser.add_argument("-g", "--grep", "--regexp", "--re", "--match",
                         dest="regexp_patterns",
                         action="append", default=[],
                         help='Grep for these patterns.')
    oparser.add_argument("--hgrep", "--hregexp", "--hmatch",
                         dest="highlight_patterns", default=[],
                         action="append",
                         help='Grep for these patterns and highlight.')
    oparser.add_argument("--wgrep", "--wregexp", "--wmatch",
                         dest="warning_regexp_patterns", default=[],
                         action="append",
                         help='Grep for these warning patterns and highlight as a warning.')

    oparser.add_argument("--grep-match-action", "--grep-hit-action",
                         dest="grep_match_action", default="",
                         type=str,
                         help="Run this when there is a pattern match.")
    oparser.add_argument("--egrep-match-action", "--egrep-hit-action",
                         dest="egrep_match_action", default="",
                         type=str,
                         help="Run this when there is an error pattern match.")
    oparser.add_argument("--hgrep-match-action", "--hgrep-hit-action",
                         dest="hgrep_match_action", default="",
                         type=str,
                         help="Run this when there is a highlight pattern match.")
    oparser.add_argument("--wgrep-match-action", "--wgrep-hit-action",
                         dest="wgrep_match_action", default="",
                         type=str,
                         help="Run this when there is a warning pattern match.")
    
    oparser.add_argument("--any-grep-matche-action","--any-grep-hit-action",
                         dest="any_grep_match_actions_p", default=False,
                         action="store_true",
                         help="Run the grep hit action on any grep hits.")
    oparser.add_argument("--project-log-errors",
                         default=None,
                         const=os.environ.get("TEEKER_PROJECT_LOG_ERROR_REGEXP",
                                              None),
                         action="store_const",
                         help="Convenience option for finding common testgen errors. Perhaps change the value of this to an envvar to make it more flexible.  --log-errors-regexp")
    oparser.add_argument("--go", "--grep-ostream", "--grep-ofile", "--reo",
                         "--regexp-ostream", "--re-ostream", "--match-ofile",
                         dest="match_ostream",
                         default=None,
                         help='Print matching lines to this stream.')
    oparser.add_argument("--max-matches", "--max-hits", "--mm",
                         dest="max_regexp_matches_before_exit",
                         type=int, default=0, # == 0 --> unlimited.
                         help="Max regexp matches before exit.")
    oparser.add_argument("--max-errors", "--max-errs", "--max-error-hits",
                         "--meh", "--emax", "--maxe",
                         dest="max_error_regexp_matches_before_exit",
                          # == 0 --> unlimited.
                         type=int, default=DEFAULT_MAX_ERROR_MATCHES,
                         help="Max error regexp matches before exit.")
    oparser.add_argument("--lines-after", "-A", "--extra-lines",
                         "--trailing-lines", "--residual_lines",
                         "--num-trailing-lines",
                         dest="num_trailing_lines",
                         type=int, default=DEFAULT_LINES_AFTER,
                         help="Print this many more lines if possible (ignoring filters and ticking) before exiting. Default is: %s. Zero means none." % (DEFAULT_LINES_AFTER,))
    oparser.add_argument("-q", "--cat-like", "--copy", "--tee",
                         nargs=0,
                         action=App_arg_action_catlike,
                         help="Just be a pass through like tee(1).")
    oparser.add_argument("--highlight-grep", "--highlight-matches",
                         "--high-grep", "--high_matches",
                         "--hl-grep", "--hl-matches",
                         "--hi-grep", "--hi-matches",
                         "--hmatches", "--h-all", "--h-ALL",
                         "--hg", "--hm", "--ha",
                         dest="highlight_ALL_grep_matches_p", default=None,
                         action="store_true",
                         help="Turn on showing of matches as they occur.")
    oparser.add_argument("--no-highlight-grep", "--no-highlight-matches",
                         "--no-high-grep", "--no-high_matches",
                         "--no-hl-grep", "--no-hl-matches",
                         "--no-hi-grep", "--no-hi-matches",
                         "--no-hgrep", "--no-hmatches",
                         "--no-hg", "--no-hm",
                         dest="highlight_ALL_grep_matches_p",
                         ## Use None as default so we can tell the difference
                         ## between the default and the option having been
                         ## specified.
                         default=None,
                         action="store_false",
                         help="Turn off showing of matches as they occur.")
    oparser.add_argument("--no-grep-summary", "--no-match-summary",
                         dest="match_summary_p", default=True,
                         action="store_false",
                         help="Don't show all grep matches at end of run.")
    oparser.add_argument("--unbuffered-logs",
                         dest="unbuffered_logs_p", default=False,
                         action="store_true")
    oparser.add_argument("--unbuffered-out",
                         dest="unbuffered_out_p", default=False,
                         action="store_true")
    
    # tee(1) compatibility.
    oparser.add_argument("-a", "--append",
                         dest="append_p", default=False,
                         action="store_true",
                         help="Append data to output file(s).")

    oparser.add_argument("output_files", nargs="*")

    # End of args. Args end.

    # Parse args.
    app_args = oparser.parse_args()

    output_files = app_args.output_files
    if app_args.optional_log_file_name:
        output_files.append(app_args.optional_log_file_name)
    output_files.extend(app_args.optional_log_file_names)

    if app_args.debug_level:
        print "app_args.debug level:", app_args.debug_level
        dp_io.set_debug_level(app_args.debug_level, enable_debugging_p=True)
        print "dp_io \debug level:", dp_io.get_debug_level()
    dp_io.cdebug(1, "app_args: %s\n", app_args)
    dp_io.cdebug(1, "Ctor_arg_dict: %s\n", Ctor_arg_dict)
    dp_io.cdebug(1, "App_arg_dict: %s\n", App_arg_dict)
    try:
        tee_p = app_args.tee_p
    except AttributeError:
        tee_p = False

    if app_args.preamble_p:
        print "Start time: {}".format(time.ctime())

    ticker_constructor = App_arg_dict.pop(CTOR)

    compress_p = app_args.compression_level >= 0

    if app_args.match_ostream is None:
        app_args.match_ostream = default_match_ostream
    else:
        mos = eval(app_args.match_ostream)
        os_type = type(mos)
        if os_type == types.StringType:
            app_args.match_ostream = open(app_args.mos, "w")
        elif os_type == types.FileType:
            app_args.match_ostream = mos
        else:
            raise exceptions.TypeError

    if app_args.show_twiddles_p:
        ticker_lib.Twiddle_twiddles()
        sys.exit(0)

    if app_args.append_p:
        open_mode = "a"

    if app_args.timestamp_log_file_names_p:
        file_suffix = "." + dp_time.std_timestamp()
    file_suffix += app_args.U_extension

    dp_io.cdebug(1, "output_files>%s<\n", output_files)
    if len(output_files) == 0 and output_files_required_p:
        dp_io.eprintf("One or more log file names are required.\n")
        sys.exit(1)

    if app_args.unbuffered_out_p:
        dp_io.unbuffer_a_file(sys.stdout)

    sample_ostream = dp_io.Unbuffered_file_duck(sys.stdout)
    compressed_file_next_flush = 0
    compressed_file_flush_period = app_args.compressed_file_flush_period

    for a in output_files:
        dp_io.cdebug(2,"log file name>%s<\n", a)
        a = a + file_suffix
        if not app_args.quiet_p:
            compression_message = ""
            if compress_p:
                compression_message = ", compression level: %d" % \
                                      (app_args.compression_level)
            dp_io.printf("output file name>%s<%s\n", a, compression_message)
        if app_args.no_clobber_p:
            if os.path.exists(a):
                dp_io.eprintf("File [%s] exists: not clobbering\n", a)
                sys.exit(1)
        if compress_p:
            dp_io.cdebug(2, "compression: %d\n", app_args.compression_level)
            fobj = gzip.open(a + ".gz", open_mode, app_args.compression_level)
            fobj = gzip.GzipFile(a + ".gz", mode=open_mode,
                                 compresslevel=app_args.compression_level)
            compressed_file_next_flush = compressed_file_flush_period
        else:
            ## Pass nothing if unbuffered is not set to preserve existing
            ## operation.
            if app_args.unbuffered_logs_p:
                fobj = open(a, open_mode, 0)
            else:
                fobj = open(a, open_mode)

        # I *love* duck typing.
        output_streams.append(fobj)


    #!<@todo Check for twiddle ticker request and handle that.
    #print "Ctor_arg_dict:", Ctor_arg_dict
    # pipe mode: Ticks go to stderr and lines go to stdout.
    pipe_mode_p, char_wise_p = (app_args.pipe_mode_p, app_args.char_wise_p)

    #if Ctor_arg_dict.get("twiddle_chars", False) != False:
    #    Ctor_arg_dict["init_string"] = ""
    #
    if Ctor_arg_dict.get("init_string", False) == False:
        if char_wise_p:
            Ctor_arg_dict["init_string"] = "Counting chars: "
            Ctor_arg_dict["unit_name"] = 'char'
        else:
            Ctor_arg_dict["init_string"] = "Counting lines: "
            Ctor_arg_dict["unit_name"] = 'line'

    if pipe_mode_p:
        Ctor_arg_dict["ostream"] = sys.stderr
    else:
        Ctor_arg_dict["ostream"] = ostream
    if app_args.sample_ALL_lines_tick_p:
        app_args.tick_interval = 1
        app_args.sample_lines_tick_p = True
    tick_interval = app_args.tick_interval
    if tick_interval == 0:
        tick_interval = None
    else:
        # No ticking --> no samples.
        if app_args.sample_lines_tick_p:
            if tick_interval == 1:
                nth = ""
            elif tick_interval == 2:
                nth = "other "
            elif tick_interval == 3:
                nth = "third "
            else:
                nth =  "%sth " % (tick_interval,)

            Ctor_arg_dict["init_string"] = "Sampling every %sline\n" % (nth,)
            Ctor_arg_dict["unit_name"] = 'line'
            Ctor_arg_dict["comma"] = ""     # Line will end with newline.

    dp_io.cdebug(1, "Final Ctor_arg_dict: %s\n", Ctor_arg_dict)
    ticker = ticker_constructor(tick_interval, **Ctor_arg_dict)
    ticker.flush()
    if pipe_mode_p:
        output_streams.append(pipe_stream)
        ostream.write("\n")

    timestamp_p = Ctor_arg_dict.get("timestamp_p", False)

    regexp_list_dict = {}               # For finding by name.
    regexp_lists = []                   # For finding in order
    if app_args.highlight_ALL_grep_matches_p:
        app_args.highlight_patterns.extend(app_args.regexp_patterns)
        app_args.regexp_patterns = []

    # The matches are dumped in order they are appended.
    l = Grep_list_t(app_args.regexp_patterns)
    regexp_list_dict["grep"] = l
    regexp_lists.append(l)

    l = Hgrep_list_t(app_args.highlight_patterns,
                     match_action=app_args.hgrep_match_action)
    regexp_list_dict["hgrep"] = l
    regexp_lists.append(l)

    if app_args.tgen_errors is not None:
        app_args.error_regexp_patterns.append(app_args.tgen_errors)

    l = Wgrep_list_t(app_args.warning_regexp_patterns,
                     match_action=app_args.wgrep_match_action)
    regexp_list_dict["wgrep"] = l
    regexp_lists.append(l)

    # Closest to the end is most noticible?
    l = Egrep_list_t(app_args.error_regexp_patterns,
                     match_action=app_args.egrep_match_action)
    regexp_list_dict["egrep"] = l
    regexp_lists.append(l)

    grepping_for_errors_p = len(app_args.error_regexp_patterns) != 0

    sampled_line_prefix = app_args.sample_lines_tick_prefix or ""
    dp_io.cdebug(2, "sampled_line_prefix>%s<\n", sampled_line_prefix)
    dp_io.cdebug(2, "app_args.sample_lines_tick_prefix>%s<\n",
                 app_args.sample_lines_tick_prefix)
    max_hits = app_args.max_regexp_matches_before_exit
    max_error_matches = app_args.max_error_regexp_matches_before_exit
    ticker.flush()
    final_exit_p = False
    limit_exit_p = False

    def loop_fini():
        dump_matching_and_error_lines(output_streams,
                                      regexp_lists,
                                      extra_streams=[sys.stdout])
        ticker.fini()

    num_trailing_lines = app_args.num_trailing_lines
    max_output_bytes_before_exit = app_args.max_output_bytes_before_exit
    trailing_line_prefix = ""
    on_borrowed_time_p = False
    while True:                         # <:main-loop:>
        readline_failed_p = False
        input_line = ""
        try:
            input_line = sys.stdin.readline()
        except Exception, e:
            dp_io.eprintf("readline() failed: %s", e)
            readline_failed_p = True
        final_exit_p = ((not input_line)
                        or readline_failed_p
                        or Caught_signals)

        limit_exit_p = ((grepping_for_errors_p and max_error_matches and
                         (len(error_lines) >= max_error_matches))
                        or ((max_output_bytes_before_exit is not False)
                            and
                            (total_bytes_written > max_output_bytes_before_exit))
                        or (max_hits and (len(matching_lines) >= max_hits)))
        #print "num_trailing_lines:", num_trailing_lines
        if (final_exit_p or limit_exit_p):
            if (final_exit_p
                or (num_trailing_lines == 0)):
                loop_fini()
                break

            # if we're here, then limit_exit_p is True and
            # num_trailing_lines is non-zero
            if not on_borrowed_time_p:
                input_line = input_line + ("\n"
                                           + "=== Post Limit Lines ==="
                                           + "\n")
                on_borrowed_time_p = True
                dp_sequences.maybe_add_to_list(output_streams, sys.stdout)
            num_trailing_lines -= 1
        input_line = trailing_line_prefix + input_line
        for o in output_streams:
            # Since this was motivated by a disk space issue, count *all*
            # writes.
            total_bytes_written += len(input_line)
            o.write(input_line)
            if ((compressed_file_next_flush is False)  # counter intuitive, neh?
                or
                (compressed_file_next_flush
                and (total_bytes_written >= compressed_file_next_flush)
                and type(o) == gzip.GzipFile)):
                o.flush()
                if compressed_file_next_flush is not False:
                    compressed_file_next_flush += compressed_file_flush_period
        if on_borrowed_time_p:
            continue
        for re_list in regexp_lists:
            re_list.match(input_line, line_number)
            
        if char_wise_p:
            # Iterate for each char in the line.
            for c in input_line:
                # Sampled lines makes no sense with char_wise.
                #if app_args.sample_lines_tick_p:
                #    tick = sampled_line_prefix + c
                #else:
                #    tick = None
                tick = None
                ticker(tick=tick)
        else:
            tick_prefix = ""
            if app_args.sample_lines_tick_p:
                # @todo XXX allow a format to be used (dictionary type)
                tick_prefix = make_tick_prefix()
                if app_args.sample_lines_tick_prefix is not False:
                    #tick = tick_counter_count_format % (ticker.counter,)
                    # very stupidtick = make_sample_tick(ticker.counter)
                    tick = TICKER_COUNT_FORMAT.format(ticker.counter)
                else:
                    tick = ""
                tick += sampled_line_prefix + input_line
            else:
                # Let the ticker class do what it will.
                tick = None
            ticker(tick=tick, tick_prefix=tick_prefix,
                   ostream=sample_ostream)
        line_number += 1
    print
    if app_args.preamble_p:
        print "End time: {}".format(time.ctime())


